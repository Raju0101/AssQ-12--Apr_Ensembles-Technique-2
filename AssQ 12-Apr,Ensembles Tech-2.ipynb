{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f211df-8737-4676-a509-c720738588f3",
   "metadata": {},
   "source": [
    "# AssQ 12- Apr Ensembles Techniques and its types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baaf48c-7604-457f-852d-670ed6edd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1915b-af5e-4608-b425-4cb56e9be548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging takes advantage of ensemble learning wherein multiple weak learners outperform a single strong learner.\n",
    "It helps reduce variance and thus helps us avoid overfitting.\n",
    "\n",
    "Bagging is a powerful ensemble method which helps to reduce variance, and by extension, prevent overfitting.\n",
    "\n",
    "Bagging attempts to reduce the chance of overfitting complex models. It trains a large number of “strong” learners in parallel. \n",
    "A strong learner is a model that's relatively unconstrained.\n",
    "Bagging then combines all the strong learners together in order to “smooth out” their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa7151-c1e6-4c3e-8b06-0c78180a667b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718632e1-f12b-46ad-b128-ba0877f2c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfdd7bd-84da-48f9-a11f-15db7d508658",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging offers the advantage of allowing many weak learners to combine efforts to outdo a single strong learner. \n",
    "It also helps in the reduction of variance, hence eliminating the overfitting of models in the procedure.\n",
    "\n",
    "The key benefits of bagging include:\n",
    "Ease of implementation: Python libraries such as scikit-learn (also known as sklearn)\n",
    "make it easy to combine the predictions of base learners or estimators to improve model performance. ...\n",
    "Reduction of variance: Bagging can reduce the variance within a learning algorithm.\n",
    "\n",
    "One disadvantage of bagging is that it introduces a loss of interpretability of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ae6c2-d920-468d-98aa-c0c8734ebc88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d81b4-27be-48af-a754-808e33be30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e4bbc-b420-4316-b06f-a2c8d9bffe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "“Bias and variance are complements of each other” The increase of one will result in the decrease of the other and vice versa.\n",
    "Hence, finding the right balance of values is known as the Bias-Variance Tradeoff.\n",
    "An ideal algorithm should neither underfit nor overfit the data.\n",
    "\n",
    "If our model is too simple and has very few parameters then it may have high bias and low variance.\n",
    "On the other hand if our model has large number of parameters then it's going to have high variance and low bias.\n",
    "\n",
    "Reducing Bias\n",
    "Change the model: One of the first stages to reducing Bias is to simply change the model. ...\n",
    "Ensure the Data is truly Representative: Ensure that the training data is diverse and represents all possible groups or outcomes. ...\n",
    "Parameter tuning: This requires an understanding of the model and model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4363f-76fe-441e-bfb8-74647ac2afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc8527-2c45-46d9-8836-c8a79d1c4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a021d6-3c04-4e63-abd4-09cc820621aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging avoids overfitting of data and is used for both regression and classification models, specifically for decision tree algorithms.\n",
    "\n",
    "Just like the decision trees themselves, Bagging can be used for classification and regression problems.\n",
    "\n",
    "In Classification Problems, Bagging use the majority vote .\n",
    "\n",
    "In Regression Problems, Bagging use the Average  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594ffce-08e6-4331-b0e0-cc4a862e9d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034821c-651d-444b-88a4-6fe289e2fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54e049-e150-41d9-8c18-1530d57a1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are no restrictions/guidelines on the number of models. You can start even from 3 models.\n",
    "You can keep the number of models as a hyperparameter if the training cost is less.\n",
    "\n",
    "The ensemble size is always 10 and the first ensemble members are trained using 95% of the data sampled without replacement. \n",
    "So the estimators are all very similar to each other. \n",
    "Then the next ensemble is trained using 90% of the data and so on.\n",
    "\n",
    "The three main classes of ensemble learning methods are bagging, stacking, and boosting, \n",
    "and it is important to both have a detailed\n",
    "understanding of each method and to consider them on your predictive modeling project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c774cf-8982-4977-b669-db5304c853a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556fbf1-c385-4dbe-909e-25824b904723",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3a902-42bb-46d4-a8d2-916f848fcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "An example of application of the bagging method would be to create a model that predicts whether \n",
    "or not a customer will churn. This could be done by training several different\n",
    "models using different data sets and then averaging their predictions together.\n",
    "\n",
    "the ensemble learning method that is commonly used to reduce variance within a noisy dataset.\n",
    "In bagging, a random sample of data in a training set is selected \n",
    "with replacement—meaning that the individual data points can be chosen more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9584620-041e-4a1a-98af-4a5c910ec162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab945e3-bc8e-46f8-93de-7668e69bd225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
